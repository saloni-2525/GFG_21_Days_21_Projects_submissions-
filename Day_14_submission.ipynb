{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install and Import Required Libraries\n",
        "print(\"Installing required packages...\")\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Install specific transformers version\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"transformers==4.36.0\"])\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(f\"âœ“ PyTorch version: {torch.__version__}\")\n",
        "print(f\"âœ“ Transformers version: {transformers.__version__}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "pM5cX705i4t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Load GPT-2 Model and Tokenizer\n",
        "print(\"Loading GPT-2 model and tokenizer...\")\n",
        "\n",
        "MODEL_NAME = \"gpt2\"  # Options: \"gpt2\", \"gpt2-medium\", \"gpt2-large\"\n",
        "\n",
        "try:\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME)\n",
        "    model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    # Set padding token to avoid warnings\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    print(f\"âœ“ Model loaded: {MODEL_NAME}\")\n",
        "    print(f\"âœ“ Parameters: {model.num_parameters():,}\")\n",
        "    print()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    sys.exit(1)"
      ],
      "metadata": {
        "id": "6QMGGvuCi8uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Python Question Filter\n",
        "def is_python_question(prompt):\n",
        "    \"\"\"\n",
        "    Determines if a prompt is related to Python programming.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): User's input question\n",
        "\n",
        "    Returns:\n",
        "        bool: True if Python-related, False otherwise\n",
        "    \"\"\"\n",
        "    prompt_lower = prompt.lower()\n",
        "\n",
        "    # Comprehensive list of Python-related keywords\n",
        "    python_keywords = [\n",
        "        # Core Python\n",
        "        'python', 'py', 'code', 'coding', 'program', 'script',\n",
        "        'function', 'def', 'class', 'method', 'variable',\n",
        "        'import', 'module', 'package', 'library',\n",
        "\n",
        "        # Data structures\n",
        "        'list', 'tuple', 'dictionary', 'dict', 'set', 'array',\n",
        "        'string', 'integer', 'float', 'boolean', 'none',\n",
        "\n",
        "        # Control flow\n",
        "        'loop', 'for', 'while', 'if', 'else', 'elif',\n",
        "        'break', 'continue', 'pass', 'return', 'yield',\n",
        "\n",
        "        # OOP\n",
        "        'object', 'inheritance', 'polymorphism', 'encapsulation',\n",
        "        'attribute', 'constructor', 'self', 'init',\n",
        "\n",
        "        # Error handling\n",
        "        'error', 'exception', 'try', 'except', 'finally',\n",
        "        'raise', 'assert', 'debug', 'traceback',\n",
        "\n",
        "        # Common operations\n",
        "        'print', 'input', 'open', 'read', 'write',\n",
        "        'append', 'sort', 'filter', 'map', 'lambda',\n",
        "\n",
        "        # Advanced concepts\n",
        "        'decorator', 'generator', 'iterator', 'comprehension',\n",
        "        'context manager', 'metaclass', 'async', 'await',\n",
        "\n",
        "        # Popular libraries\n",
        "        'numpy', 'pandas', 'matplotlib', 'scipy', 'sklearn',\n",
        "        'tensorflow', 'pytorch', 'django', 'flask', 'requests',\n",
        "\n",
        "        # File operations\n",
        "        'file', 'csv', 'json', 'xml', 'pickle',\n",
        "\n",
        "        # Other\n",
        "        'syntax', 'indentation', 'pep', 'pythonic',\n",
        "        'pip', 'virtual environment', 'venv', 'conda',\n",
        "        'algorithm', 'data structure', 'recursion'\n",
        "    ]\n",
        "\n",
        "    # Check for keywords\n",
        "    for keyword in python_keywords:\n",
        "        if keyword in prompt_lower:\n",
        "            return True\n",
        "\n",
        "    # Check for common Python patterns using regex\n",
        "    python_patterns = [\n",
        "        r'how to .* in python',\n",
        "        r'python .* code',\n",
        "        r'write .* function',\n",
        "        r'create .* class',\n",
        "        r'implement .*',\n",
        "        r'\\.py\\b',\n",
        "        r'def\\s+\\w+\\(',\n",
        "        r'import\\s+\\w+',\n",
        "        r'from\\s+\\w+\\s+import',\n",
        "        r'write.*program',\n",
        "        r'solve.*python',\n",
        "    ]\n",
        "\n",
        "    for pattern in python_patterns:\n",
        "        if re.search(pattern, prompt_lower):\n",
        "            return True\n",
        "\n",
        "    return False"
      ],
      "metadata": {
        "id": "vz2DyLcZjFhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: Response Generation\n",
        "def generate_python_response(prompt, max_length=200, temperature=0.7):\n",
        "    \"\"\"\n",
        "    Generates a response using GPT-2 for Python coding questions.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): The input prompt\n",
        "        max_length (int): Maximum length of generated text\n",
        "        temperature (float): Sampling temperature (0.0 to 1.0)\n",
        "\n",
        "    Returns:\n",
        "        str: Generated response\n",
        "    \"\"\"\n",
        "    # Enhance prompt for better coding responses\n",
        "    enhanced_prompt = f\"Python programming Q&A:\\n\\nQuestion: {prompt}\\n\\nAnswer:\"\n",
        "\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer.encode(enhanced_prompt, return_tensors=\"pt\")\n",
        "    attention_mask = torch.ones(inputs.shape, dtype=torch.long)\n",
        "\n",
        "    # Generate response\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=max_length,\n",
        "            temperature=temperature,\n",
        "            num_return_sequences=1,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            no_repeat_ngram_size=2,\n",
        "            repetition_penalty=1.2\n",
        "        )\n",
        "\n",
        "    # Decode and clean response\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract only the answer part\n",
        "    if \"Answer:\" in response:\n",
        "        response = response.split(\"Answer:\")[-1].strip()\n",
        "\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "jrp3UrX4jNn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl7c595ChCq9"
      },
      "outputs": [],
      "source": [
        "# STEP 5: Main Chatbot Function\n",
        "def python_chatbot(user_question):\n",
        "    \"\"\"\n",
        "    Main chatbot function that filters questions and generates responses.\n",
        "\n",
        "    Args:\n",
        "        user_question (str): User's input question\n",
        "\n",
        "    Returns:\n",
        "        str: Response from the chatbot\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Question: {user_question}\")\n",
        "    print('='*70)\n",
        "\n",
        "    # Check if it's a Python question\n",
        "    if is_python_question(user_question):\n",
        "        print(\"âœ“ Python coding question detected. Generating response...\\n\")\n",
        "\n",
        "        response = generate_python_response(user_question)\n",
        "        print(f\"Answer:\\n{response}\")\n",
        "\n",
        "        return response\n",
        "    else:\n",
        "        print(\"âœ— Not a Python coding question.\\n\")\n",
        "\n",
        "        rejection_message = (\n",
        "            \"I'm sorry, but I'm specialized in answering Python programming questions only. \"\n",
        "            \"Please ask me something related to Python coding, such as:\\n\"\n",
        "            \"  â€¢ How to use lists in Python?\\n\"\n",
        "            \"  â€¢ Write a function to sort a dictionary\\n\"\n",
        "            \"  â€¢ How to handle exceptions in Python?\\n\"\n",
        "            \"  â€¢ What is list comprehension?\"\n",
        "        )\n",
        "\n",
        "        print(f\"Answer:\\n{rejection_message}\")\n",
        "        return rejection_message\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: Interactive Mode\n",
        "def interactive_mode():\n",
        "    \"\"\"\n",
        "    Interactive chatbot mode for continuous Q&A.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PYTHON CODING ASSISTANT - INTERACTIVE MODE\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"I'm a specialized chatbot trained to answer Python coding questions!\")\n",
        "    print(\"\\nCommands:\")\n",
        "    print(\"  â€¢ Type your Python question to get an answer\")\n",
        "    print(\"  â€¢ Type 'examples' to see example questions\")\n",
        "    print(\"  â€¢ Type 'quit', 'exit', or 'q' to exit\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"ðŸ’¬ Your question: \").strip()\n",
        "\n",
        "        # Exit commands\n",
        "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
        "            print(\"\\nThank you for using Python Coding Assistant. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Empty input\n",
        "        if not user_input:\n",
        "            print(\"Please enter a question.\\n\")\n",
        "            continue\n",
        "\n",
        "        # Show examples\n",
        "        if user_input.lower() == 'examples':\n",
        "            print(\"\\nExample Python Questions:\")\n",
        "            print(\"  â€¢ How do I create a dictionary in Python?\")\n",
        "            print(\"  â€¢ Write a function to reverse a string\")\n",
        "            print(\"  â€¢ What is the difference between list and tuple?\")\n",
        "            print(\"  â€¢ How to read a CSV file in Python?\")\n",
        "            print(\"  â€¢ Explain list comprehension with examples\")\n",
        "            print(\"  â€¢ How to handle FileNotFoundError?\")\n",
        "            print(\"  â€¢ What are decorators in Python?\\n\")\n",
        "            continue\n",
        "\n",
        "        # Process question\n",
        "        python_chatbot(user_input)\n",
        "        print()\n",
        "\n"
      ],
      "metadata": {
        "id": "H5Xa4DYRjoPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 7: Testing Suite\n",
        "def run_tests():\n",
        "    \"\"\"\n",
        "    Runs a series of test cases to demonstrate the chatbot.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"RUNNING TEST CASES\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    test_cases = [\n",
        "        # Python questions\n",
        "        \"How do I create a list in Python?\",\n",
        "        \"Write a function to calculate factorial\",\n",
        "        \"What is the difference between list and tuple?\",\n",
        "        \"How to handle IndexError in Python?\",\n",
        "        \"Explain lambda functions\",\n",
        "\n",
        "        # Non-Python questions\n",
        "        \"What is the capital of France?\",\n",
        "        \"Tell me a joke\",\n",
        "        \"What's the weather today?\",\n",
        "        \"Who won the World Cup?\"\n",
        "    ]\n",
        "\n",
        "    for i, question in enumerate(test_cases, 1):\n",
        "        print(f\"\\n--- Test Case {i} ---\")\n",
        "        python_chatbot(question)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"âœ“ ALL TESTS COMPLETED\")\n",
        "    print(\"=\"*70)\n"
      ],
      "metadata": {
        "id": "KMkptZKAjqjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 8: Main Execution\n",
        "# ============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PYTHON-FOCUSED GPT-2 CHATBOT INITIALIZED\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # First, run automated tests to show examples\n",
        "    run_tests()\n",
        "\n",
        "    # After tests, ask if user wants to try interactive mode\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    user_choice = input(\"\\nWould you like to try the interactive mode? (yes/no): \").strip().lower()\n",
        "\n",
        "    if user_choice in ['yes', 'y']:\n",
        "        interactive_mode()\n",
        "    else:\n",
        "        print(\"\\nThank you for testing! You can uncomment interactive_mode() to chat anytime.\")\n",
        "\n",
        "print(\"\\nâœ“ Program completed successfully!\")"
      ],
      "metadata": {
        "id": "qXVMt0z7kKWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2kwuyVVPkksc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}