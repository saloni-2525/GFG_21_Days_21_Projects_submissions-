{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJIn3LX98GxW"
      },
      "source": [
        "# Hugging Face Pipelines Demo\n",
        "\n",
        "This notebook demonstrates how to use the **Hugging Face `transformers` library** for a variety of natural language processing and computer vision tasks. Each section introduces a pipeline, loads a pre-trained model, and shows example usage.\n",
        "\n",
        "## Covered Tasks\n",
        "1. **Sentiment Analysis** – Classify text sentiment (positive/negative).  \n",
        "2. **Text Summarization** – Generate concise summaries of long text.  \n",
        "3. **Question Answering** – Answer questions from a given context.  \n",
        "4. **Named Entity Recognition (NER)** – Extract entities like names, dates, and organizations.  \n",
        "5. **Text Generation** – Generate coherent text given a prompt.  \n",
        "6. **Image Classification** – Classify objects in an image.  \n",
        "7. **Object Detection** – Detect and localize objects in an image.  \n",
        "8. **Image Segmentation** – Segment different objects in an image.  \n",
        "9. **Translation** – Translate text between languages.  \n",
        "10. **Zero-Shot Classification** – Classify text without task-specific training.  \n",
        "11. **Image Captioning** – Generate descriptive captions for images.  \n",
        "\n",
        "## Requirements\n",
        "- `transformers`  \n",
        "- `torch`  \n",
        "- `requests`  \n",
        "- `PIL`  \n",
        "- `matplotlib`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpLmpwTV7Nv5"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from transformers import pipeline\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGLQtC5b1lYj"
      },
      "source": [
        "## 1. Sentiment Analysis\n",
        "\n",
        "Sentiment analysis is the task of determining the emotional tone behind a piece of text. It helps identify whether the sentiment expressed is positive, negative, or neutral. This is widely used in analyzing customer feedback, social media monitoring, and understanding public opinion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ca41f17"
      },
      "outputs": [],
      "source": [
        "sentiment_analyzer = pipeline('sentiment-analysis')\n",
        "\n",
        "text = \"Thanks, Google, I didn’t know that already\"\n",
        "result = sentiment_analyzer(text)\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21608234"
      },
      "source": [
        "## 2. Text Summarization\n",
        "\n",
        "Text summarization is the task of creating a shorter version of a text that still conveys the main points and information of the original document. It is useful for quickly understanding the content of long articles, reports, or documents, and for generating concise previews or summaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c1a66c9"
      },
      "outputs": [],
      "source": [
        "summarizer = pipeline('summarization')\n",
        "\n",
        "text = \"\"\"\n",
        "Hugging Face is an artificial intelligence company based in New York City and Paris. It is most famous for its Transformers library, a Python library for building, training, and deploying models based on the transformer architecture. The library is widely used for natural language processing tasks such as text classification, sentiment analysis, question answering, and text generation. Hugging Face also provides a platform for hosting and sharing machine learning models, datasets, and demos. The company has become a central hub for the open-source AI community, with a focus on democratizing AI through open models and tools.\n",
        "\"\"\"\n",
        "\n",
        "summary = summarizer(text, max_length=50, min_length=10, do_sample=False)\n",
        "\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0865ba5"
      },
      "source": [
        "## 3. Question Answering\n",
        "\n",
        "Question Answering is the task of extracting an answer to a question from a given text (context). The model reads the context and finds the span of text that best answers the question. This is particularly useful for building chatbots, information retrieval systems, and educational tools where users need quick answers from documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b34fee6"
      },
      "outputs": [],
      "source": [
        "question_answerer = pipeline('question-answering')\n",
        "\n",
        "context = \"\"\"\n",
        "Hugging Face is an artificial intelligence company based in New York City and Paris. It is most famous for its Transformers library, a Python library for building, training, and deploying models based on the transformer architecture. The library is widely used for natural language processing tasks such as text classification, sentiment analysis, question answering, and text generation. Hugging Face also provides a platform for hosting and sharing machine learning models, datasets, and demos. The company has become a central hub for the open-source AI community, with a focus on democratizing AI through open models and tools.\n",
        "\"\"\"\n",
        "question = \"Where is Hugging Face based?\"\n",
        "\n",
        "answer = question_answerer(question=question, context=context)\n",
        "\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c742e6ed"
      },
      "source": [
        "## 4. Named Entity Recognition (NER)\n",
        "\n",
        "Named Entity Recognition (NER) is the task of identifying and classifying named entities in text into predefined categories such as person names, organizations, locations, dates, etc. It helps in extracting structured information from unstructured text and is fundamental for many downstream NLP tasks like information extraction, question answering, and text summarization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da28c1b4"
      },
      "outputs": [],
      "source": [
        "ner_pipeline = pipeline('ner', grouped_entities=True)\n",
        "\n",
        "text = \"Hugging Face is a company located in New York City and Paris.\"\n",
        "\n",
        "entities = ner_pipeline(text)\n",
        "\n",
        "print(entities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31c8c913"
      },
      "source": [
        "## 5. Text Generation\n",
        "\n",
        "Text Generation is the task of creating new text based on a given prompt or starting text. The model predicts the next word or sequence of words, allowing for the creation of stories, articles, poems, code, and more. It is a fundamental capability for applications like chatbots, content creation tools, and creative writing assistants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c5b94b8"
      },
      "outputs": [],
      "source": [
        "text_generator = pipeline('text-generation')\n",
        "\n",
        "prompt = \"The quick brown fox jumps over the lazy\"\n",
        "\n",
        "generated_text = text_generator(prompt, max_length=30, num_return_sequences=1)\n",
        "\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMVVm1b-tKLt"
      },
      "outputs": [],
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "# from transformers import pipeline\n",
        "\n",
        "# pipe = pipeline(\"text-generation\", model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\")\n",
        "# messages = [\n",
        "#     {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "# ]\n",
        "# pipe(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da2a8a24"
      },
      "source": [
        "## 6. Image classification\n",
        "\n",
        "Image Classification is the task of assigning a label or category to an entire image. The model analyzes the visual content of an image and predicts what it represents, choosing from a predefined set of classes. This is a fundamental task in computer vision with applications ranging from organizing photo libraries and content moderation to medical image analysis and autonomous driving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKHeOGc2T_dh"
      },
      "outputs": [],
      "source": [
        "image_classifier = pipeline(\"image-classification\")\n",
        "\n",
        "image_url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "response = requests.get(image_url)\n",
        "image = Image.open(BytesIO(response.content))\n",
        "\n",
        "classification_results = image_classifier(image)\n",
        "\n",
        "print(classification_results)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17786ab1"
      },
      "source": [
        "## 7. Object Detection\n",
        "\n",
        "Object Detection is a computer vision task that involves identifying and locating instances of predefined objects within an image or video. It not only classifies what objects are present but also provides their precise location using bounding boxes. This is crucial for applications like autonomous driving, surveillance, image search, and robotics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9c0e5f2"
      },
      "outputs": [],
      "source": [
        "object_detector = pipeline(\"object-detection\")\n",
        "\n",
        "image_url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "response = requests.get(image_url)\n",
        "image = Image.open(BytesIO(response.content))\n",
        "\n",
        "detection_results = object_detector(image)\n",
        "print(detection_results)\n",
        "\n",
        "draw = ImageDraw.Draw(image)\n",
        "for obj in detection_results:\n",
        "    box = obj[\"box\"]\n",
        "    label = obj[\"label\"]\n",
        "    score = obj[\"score\"]\n",
        "\n",
        "    # Draw rectangle\n",
        "    draw.rectangle(\n",
        "        [(box[\"xmin\"], box[\"ymin\"]), (box[\"xmax\"], box[\"ymax\"])],\n",
        "        outline=\"red\", width=3\n",
        "    )\n",
        "    # Add label + score\n",
        "    draw.text((box[\"xmin\"], box[\"ymin\"] - 10), f\"{label} ({score:.2f})\", fill=\"red\")\n",
        "\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "883453dc"
      },
      "source": [
        "## 8. Image Segmentation\n",
        "\n",
        "Image Segmentation is a computer vision task that involves partitioning an image into multiple segments or regions, often to identify and delineate objects or areas of interest at a pixel level. Unlike object detection which draws bounding boxes, segmentation provides a more detailed understanding of the image by outlining the exact shape of objects. It is used in applications like medical imaging, autonomous driving, and image editing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4bd7548"
      },
      "outputs": [],
      "source": [
        "image_segmentor = pipeline(\"image-segmentation\")\n",
        "\n",
        "image_url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "response = requests.get(image_url)\n",
        "image = Image.open(BytesIO(response.content))\n",
        "\n",
        "segmentation_results = image_segmentor(image)\n",
        "print(segmentation_results)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Original Image\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i, result in enumerate(segmentation_results):\n",
        "    mask = result[\"mask\"]  # segmentation mask\n",
        "    label = result[\"label\"]\n",
        "    plt.subplot(1, len(segmentation_results), i+1)\n",
        "    plt.imshow(mask)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(label)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZiPSQMX50e2"
      },
      "source": [
        "## 9. Translation\n",
        "\n",
        "Machine Translation is the task of automatically converting text from one language to another. It allows for communication across language barriers and is used in various applications, including real-time translation services, document translation, and localization of software and content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76e4983c"
      },
      "outputs": [],
      "source": [
        "translator = pipeline('translation', model='Helsinki-NLP/opus-mt-en-fr')\n",
        "\n",
        "english_text = \"Hello, how are you today?\"\n",
        "\n",
        "translated_text = translator(english_text)\n",
        "\n",
        "print(translated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06082985"
      },
      "source": [
        "## 10. Zero-Shot Classification\n",
        "\n",
        "Zero-Shot Classification is a machine learning task where the model is able to classify instances into categories it has not seen during training. Instead of learning to classify based on example data for each category, it uses descriptions or embeddings of the categories. This is particularly powerful when dealing with a large number of potential classes or when new classes emerge frequently, reducing the need for extensive labeled training data for every new category. It relies on the model's ability to generalize from learned concepts to new, unseen ones based on the semantic relationship between the input and the category descriptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f24ada45"
      },
      "outputs": [],
      "source": [
        "zero_shot_classifier = pipeline('zero-shot-classification')\n",
        "\n",
        "sequence_to_classify = \"This is a great movie about the future of AI.\"\n",
        "\n",
        "candidate_labels = [\"politics\", \"technology\", \"entertainment\", \"business\"]\n",
        "\n",
        "classification_results = zero_shot_classifier(sequence_to_classify, candidate_labels)\n",
        "\n",
        "print(classification_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ff73f25"
      },
      "source": [
        "## 11. Image Captioning\n",
        "\n",
        "Image Captioning is a multimodal task that involves generating a descriptive text caption for an image. It requires a model to understand both the visual content of an image and be able to generate coherent and relevant language. This task bridges the gap between computer vision and natural language processing and has applications in accessibility (describing images for visually impaired users), image indexing and search, and generating descriptions for products or content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c2a0498"
      },
      "outputs": [],
      "source": [
        "image_captioner = pipeline('image-to-text', model=\"Salesforce/blip-image-captioning-base\")\n",
        "print(\"Image-to-text pipeline loaded.\")\n",
        "\n",
        "image_url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "\n",
        "response = requests.get(image_url)\n",
        "image = Image.open(BytesIO(response.content))\n",
        "\n",
        "caption_results = image_captioner(image)\n",
        "print(\"Generated Caption:\", caption_results)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.title(caption_results[0][\"generated_text\"], fontsize=12, color=\"blue\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d758763d"
      },
      "source": [
        "## Project Summary\n",
        "\n",
        "This notebook provides a hands-on introduction to various natural language processing and computer vision tasks using the Hugging Face `transformers` library. We explored the following pipelines:\n",
        "\n",
        "-   **Sentiment Analysis:** Classifying text sentiment.\n",
        "-   **Text Summarization:** Generating concise summaries of text.\n",
        "-   **Question Answering:** Extracting answers from a given context.\n",
        "-   **Named Entity Recognition (NER):** Identifying and classifying named entities in text.\n",
        "-   **Text Generation:** Creating new text based on a prompt.\n",
        "-   **Image Classification:** Assigning a label to an entire image.\n",
        "-   **Object Detection:** Identifying and locating objects in an image with bounding boxes.\n",
        "-   **Image Segmentation:** Partitioning an image into multiple segments to delineate objects.\n",
        "-   **Translation:** Converting text from one language to another.\n",
        "-   **Zero-Shot Classification:** Classifying text into categories not seen during training.\n",
        "-   **Image Captioning:** Generating descriptive text captions for images.\n",
        "\n",
        "Each section demonstrated how to load the respective pipeline and apply it to example data, showcasing the power and ease of use of the Hugging Face ecosystem for various AI tasks. The notebook concludes with an assignment task to explore image generation using diffusion models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dca76c01"
      },
      "source": [
        "## Assignment: Image Generation with Diffusion Models\n",
        "\n",
        "For this assignment, you will explore the use of diffusion models for image generation using the Hugging Face `transformers` library.\n",
        "\n",
        "Take any model from https://huggingface.co/stabilityai\n",
        "\n",
        "**Task:**\n",
        "\n",
        "1.  **Choose a Diffusion Model:** Select a diffusion model available on the Hugging Face Hub. You can explore models from popular libraries like `diffusers`.\n",
        "2.  **Load the Pipeline:** Load the appropriate pipeline for image generation using the chosen diffusion model.\n",
        "3.  **Generate Images:** Generate one or more images using the pipeline with different prompts and parameters.\n",
        "4.  **Display and Discuss:** Display the generated images and write a brief discussion about:\n",
        "    *   The model you chose and why.\n",
        "    *   The prompts and parameters you used for generation.\n",
        "    *   Your observations about the quality and characteristics of the generated images.\n",
        "    *   Any challenges or interesting findings you encountered.\n",
        "\n",
        "**Requirements:**\n",
        "\n",
        "*   Your code should be in a new code cell following this markdown section.\n",
        "*   Clearly indicate the model you are using in your code or discussion.\n",
        "*   Use `matplotlib` or other appropriate libraries to display the generated images within the notebook.\n",
        "*   Provide a clear and concise discussion of your work in a markdown cell below the code.\n",
        "\n",
        "This assignment will give you hands-on experience with state-of-the-art image generation techniques using the powerful tools provided by Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "pipe = pipe.to(\"cuda\")   # T4 GPU\n",
        "\n",
        "prompt = \"ultra detailed, 4k, photorealistic portrait of a young Indian engineer working on a laptop, in a modern office, soft natural lighting\"\n",
        "\n",
        "image = pipe(\n",
        "    prompt,\n",
        "    height=512,     # start small\n",
        "    width=512,\n",
        "    num_inference_steps=25,\n",
        "    guidance_scale=7.5,\n",
        ").images[0]\n",
        "\n",
        "image.save(\"sd15_example.png\")\n",
        "display(image)\n"
      ],
      "metadata": {
        "id": "hajCc-0wPmgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H_HVInLgPm_k"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}