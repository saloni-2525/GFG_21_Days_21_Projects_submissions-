{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 12033863,
          "sourceType": "datasetVersion",
          "datasetId": 7571831
        }
      ],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stock Price Prediction (NIFTY 50)\n",
        "\n",
        "This project focuses on predicting **NIFTY 50 stock prices** using both **Machine Learning (ML)** and **Deep Learning (DL)** approaches.  \n",
        "The workflow involves preparing time-series data, training multiple models, and comparing their performance.\n",
        "\n",
        "---\n",
        "\n",
        "## Pipeline Overview\n",
        "\n",
        "1. **Data Loading**\n",
        "   - Load stock price data (`data.csv`).\n",
        "   - Features: `Open`, `Close`, `High`, `Low`.\n",
        "\n",
        "2. **Data Preparation**\n",
        "   - Create supervised learning datasets using sliding windows (30–250 days).\n",
        "   - Generate `(X, y)` pairs for each feature.\n",
        "\n",
        "3. **Modeling**\n",
        "   - **Machine Learning Models**  \n",
        "     - Linear: `LinearRegression`, `Ridge`, `Lasso`  \n",
        "     - Tree-based: `RandomForest`, `GradientBoosting`, `XGBoost`, `LightGBM`  \n",
        "     - Others: `SVR`, `KNN`\n",
        "   - **Deep Learning Models**  \n",
        "     - RNN, LSTM, GRU, Bidirectional LSTM (Keras Sequential API)\n",
        "\n",
        "4. **Training**\n",
        "   - Train models on rolling window datasets.\n",
        "   - Evaluate using **MAE** and **RMSE**.\n",
        "\n",
        "5. **Evaluation & Comparison**\n",
        "   - Store results for all models.\n",
        "   - Compare ML vs DL models for different input window sizes.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Highlights\n",
        "- Hybrid pipeline combining **classical ML** and **neural networks**.  \n",
        "- Uses **multiple time horizons (30–250 days)** for robust prediction.  \n",
        "- Tracks **training and testing errors** to evaluate generalization.  "
      ],
      "metadata": {
        "id": "837BQmv01ffh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Import Libraries & Dataset"
      ],
      "metadata": {
        "id": "mYcX03TMmmWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Import Libraries**\n",
        "   - `numpy`, `pandas`: data handling  \n",
        "   - `tqdm`: progress bars  \n",
        "   - `sklearn`: machine learning models & metrics  \n",
        "   - `xgboost`, `lightgbm`: gradient boosting models  \n",
        "   - `warnings`: ignore warnings  \n",
        "\n",
        "2. **Load Dataset**\n",
        "   - `df = pd.read_csv('data.csv')` → load data from CSV  \n",
        "   - `df.head()` → preview first 5 rows  \n",
        "\n",
        "3. **Models Imported**\n",
        "   - Linear: `LinearRegression`, `Ridge`, `Lasso`  \n",
        "   - Tree-based: `RandomForestRegressor`, `GradientBoostingRegressor`  \n",
        "   - Others: `SVR`, `KNeighborsRegressor`, `XGBRegressor`, `LGBMRegressor`  \n",
        "\n",
        "4. **Metrics Imported**\n",
        "   - `mean_absolute_error`, `mean_squared_error` → to evaluate model performance  \n"
      ],
      "metadata": {
        "id": "8XCf_7dEzAHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-06T17:51:35.605215Z",
          "iopub.execute_input": "2025-06-06T17:51:35.605834Z",
          "iopub.status.idle": "2025-06-06T17:51:35.628024Z",
          "shell.execute_reply.started": "2025-06-06T17:51:35.605807Z",
          "shell.execute_reply": "2025-06-06T17:51:35.627363Z"
        },
        "id": "SvNjJGZhLZDm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Data Preparation"
      ],
      "metadata": {
        "id": "o2C2h8tXmzZ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Train-Test Split**\n",
        "   - `train_test_split()` → split data into training & testing sets.  \n",
        "\n",
        "2. **Models List**\n",
        "   - A collection of regressors:  \n",
        "     - Linear: `LinearRegression`, `Ridge`, `Lasso`  \n",
        "     - Tree-based: `RandomForestRegressor`, `GradientBoostingRegressor`  \n",
        "     - Others: `SVR`, `KNeighborsRegressor`, `XGBRegressor`, `LGBMRegressor`  \n",
        "\n",
        "3. **Training Loop**\n",
        "   - For each model:  \n",
        "     - `fit()` → train on training data  \n",
        "     - `predict()` → generate predictions on test data  \n",
        "\n",
        "4. **Evaluation**\n",
        "   - Metrics used:  \n",
        "     - `mean_absolute_error`  \n",
        "     - `mean_squared_error`  \n",
        "   - Store results for comparison of all models.  "
      ],
      "metadata": {
        "id": "On4HUmb7zKMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def return_pairs(column, days):\n",
        "    pricess = list(column)\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(pricess) - days):\n",
        "        X.append(pricess[i:i+days])\n",
        "        y.append(pricess[i+days])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "target_columns =  ['Open', 'Close', 'High', 'Low']\n",
        "day_chunks = [30, 60, 90]\n",
        "# day_chunks =  [30, 45, 60, 90, 120, 150 ,200, 250]\n",
        "\n",
        "chunked_data = {}\n",
        "\n",
        "for col in target_columns:\n",
        "    for days in day_chunks:\n",
        "        key_X = f\"X_{col}_{days}\"\n",
        "        key_y = f\"y_{col}_{days}\"\n",
        "        X, y = return_pairs(df[col], days)\n",
        "        chunked_data[key_X] = X\n",
        "        chunked_data[key_y] = y\n",
        "\n",
        "\n",
        "chunk_pairs = []\n",
        "\n",
        "for key in chunked_data.keys():\n",
        "    if key.startswith(\"X_\"):\n",
        "        y_key = key.replace(\"X_\", \"y_\")\n",
        "        if y_key in chunked_data:\n",
        "            chunk_pairs.append([key, y_key])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-06T17:51:35.764313Z",
          "iopub.execute_input": "2025-06-06T17:51:35.764702Z",
          "iopub.status.idle": "2025-06-06T17:51:37.352837Z",
          "shell.execute_reply.started": "2025-06-06T17:51:35.764682Z",
          "shell.execute_reply": "2025-06-06T17:51:37.352248Z"
        },
        "id": "oR_G9WHYLZDn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Define Neural Network Models"
      ],
      "metadata": {
        "id": "ayjEKlO8nAke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Imports**\n",
        "   - `Sequential` → build models layer-by-layer  \n",
        "   - Layers: `Dense`, `SimpleRNN`, `LSTM`, `GRU`, `Bidirectional`  \n",
        "\n",
        "2. **Model Builder Functions**\n",
        "   - `build_rnn(input_shape)`  \n",
        "     - Simple RNN with 50 units → `Dense(1)` output  \n",
        "   - `build_lstm(input_shape)`  \n",
        "     - LSTM with 50 units → `Dense(1)` output  \n",
        "   - `build_gru(input_shape)`  \n",
        "     - GRU with 50 units → `Dense(1)` output  \n",
        "   - `build_bilstm(input_shape)`  \n",
        "     - Bidirectional LSTM with 50 units → `Dense(1)` output  \n",
        "\n",
        "3. **Compilation**\n",
        "   - Optimizer: `adam`  \n",
        "   - Loss: `mse` (Mean Squared Error)  \n",
        "\n",
        "4. **Purpose**\n",
        "   - All models → designed for **regression tasks on sequential data**.  "
      ],
      "metadata": {
        "id": "8WyY8z9gzRYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU, Bidirectional\n",
        "\n",
        "\n",
        "def build_rnn(input_shape):\n",
        "    model = Sequential([\n",
        "        SimpleRNN(50, activation='tanh', input_shape=input_shape),\n",
        "        Dense(1)   # regression output\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(50, activation='tanh', input_shape=input_shape),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "def build_gru(input_shape):\n",
        "    model = Sequential([\n",
        "        GRU(50, activation='tanh', input_shape=input_shape),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "def build_bilstm(input_shape):\n",
        "    model = Sequential([\n",
        "        Bidirectional(LSTM(50, activation='tanh'), input_shape=input_shape),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model"
      ],
      "metadata": {
        "id": "_7c8mEVZMILG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Define ML Models"
      ],
      "metadata": {
        "id": "oSe33wQJnE74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **ml_models (Traditional ML)**\n",
        "   - A list of tuples: (name, model instance)  \n",
        "   - Includes:  \n",
        "     - Linear models → `LinearRegression`, `Ridge`, `Lasso`  \n",
        "     - Tree-based → `RandomForest`, `GradientBoosting`  \n",
        "     - Others → `SVR`, `KNN`, `XGBoost`, `LightGBM`  \n",
        "\n",
        "2. **dl_models (Deep Learning)**\n",
        "   - A dictionary: {name: builder function}  \n",
        "   - Includes:  \n",
        "     - `\"RNN\"` → `build_rnn`  \n",
        "     - `\"LSTM\"` → `build_lstm`  \n",
        "     - `\"GRU\"` → `build_gru`  \n",
        "     - `\"Bidirectional_LSTM\"` → `build_bilstm`  \n",
        "\n",
        "3. **Purpose**\n",
        "   - `ml_models`: ready-to-train classical ML regressors  \n",
        "   - `dl_models`: functions that return compiled neural nets (when given `input_shape`)  "
      ],
      "metadata": {
        "id": "7GR2d1B9zWjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_models = [\n",
        "    (\"LinearRegression\", LinearRegression()),\n",
        "    (\"Ridge\", Ridge()),\n",
        "    (\"Lasso\", Lasso()),\n",
        "    (\"RandomForest\", RandomForestRegressor()),\n",
        "    (\"GradientBoosting\", GradientBoostingRegressor()),\n",
        "    (\"SVR\", SVR()),\n",
        "    (\"KNN\", KNeighborsRegressor()),\n",
        "    (\"XGBoost\", XGBRegressor(verbosity=0)),\n",
        "    (\"LightGBM\", LGBMRegressor(verbosity=0))\n",
        "]\n",
        "\n",
        "dl_models = {\n",
        "    \"RNN\": build_rnn,\n",
        "    \"LSTM\": build_lstm,\n",
        "    \"GRU\": build_gru,\n",
        "    \"Bidirectional_LSTM\": build_bilstm\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-06T17:51:37.353951Z",
          "iopub.execute_input": "2025-06-06T17:51:37.354171Z",
          "iopub.status.idle": "2025-06-06T17:51:37.358468Z",
          "shell.execute_reply.started": "2025-06-06T17:51:37.354144Z",
          "shell.execute_reply": "2025-06-06T17:51:37.357811Z"
        },
        "id": "cm7cmgElLZDn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Model Training"
      ],
      "metadata": {
        "id": "76XqOB5KnPnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Initialize**\n",
        "   - `trained_models = {}` → store results of all models  \n",
        "\n",
        "2. **Iterate over Data Pairs**\n",
        "   - For each `(X, y)` in `chunk_pairs`  \n",
        "   - Extract features `X_data` and target `y_data` from `chunked_data`  \n",
        "   - Split → `train_test_split` (90% train, 10% test)  \n",
        "\n",
        "3. **Train ML Models**\n",
        "   - Loop through `ml_models`  \n",
        "   - Use `deepcopy` to avoid reusing fitted models  \n",
        "   - `fit()` on training data  \n",
        "   - Predict on train & test sets  \n",
        "   - Save model + metrics:  \n",
        "     - `train_mae`, `train_rmse`  \n",
        "     - `test_mae`, `test_rmse`  \n",
        "\n",
        "4. **Prepare Data for DL**\n",
        "   - Expand dims → shape becomes `(samples, timesteps, features)`  \n",
        "\n",
        "5. **Train DL Models**\n",
        "   - Loop through `dl_models`  \n",
        "   - Build model with correct input shape  \n",
        "   - Train for 10 epochs, batch size = 8  \n",
        "   - Predict on train & test  \n",
        "   - Save model + metrics (same as ML)  \n",
        "\n",
        "6. **Final Output**\n",
        "   - `trained_models` → dictionary with all trained models & evaluation scores  \n"
      ],
      "metadata": {
        "id": "Mj2YfY1-zZUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "trained_models = {}\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=2,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "for X, y in tqdm(chunk_pairs):\n",
        "    X_data = chunked_data[X]\n",
        "    y_data = chunked_data[y]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_data, y_data, test_size=0.1, random_state=42\n",
        "    )\n",
        "\n",
        "    # ML models\n",
        "    for model_name, model in tqdm(ml_models):\n",
        "        key = model_name + '_' + X\n",
        "# key = model_name + '_' + X[2:]\n",
        "        model_copy = deepcopy(model)\n",
        "        model_copy.fit(X_train, y_train)\n",
        "\n",
        "        y_train_pred = model_copy.predict(X_train)\n",
        "        y_test_pred = model_copy.predict(X_test)\n",
        "\n",
        "        trained_models[key] = {\n",
        "            'model': model_copy,\n",
        "            'train_mae': mean_absolute_error(y_train, y_train_pred),\n",
        "            'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
        "            'test_mae': mean_absolute_error(y_test, y_test_pred),\n",
        "            'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "        }\n",
        "\n",
        "    # DL models\n",
        "    X_train_rnn = np.expand_dims(X_train, -1)\n",
        "    X_test_rnn = np.expand_dims(X_test, -1)\n",
        "\n",
        "    for model_name, builder in tqdm(dl_models.items()):\n",
        "        key = model_name + '_' + X[2:]\n",
        "        model_dl = builder((X_train.shape[1], 1))\n",
        "\n",
        "        model_dl.fit(X_train_rnn, y_train, epochs=8, batch_size=32,validation_split=0.1, callbacks=[early_stop], verbose=1)\n",
        "\n",
        "        y_train_pred = model_dl.predict(X_train_rnn).flatten()\n",
        "        y_test_pred = model_dl.predict(X_test_rnn).flatten()\n",
        "\n",
        "        trained_models[key] = {\n",
        "            'model': model_dl,\n",
        "            'train_mae': mean_absolute_error(y_train, y_train_pred),\n",
        "            'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
        "            'test_mae': mean_absolute_error(y_test, y_test_pred),\n",
        "            'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "        }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-06T17:52:18.064953Z",
          "iopub.execute_input": "2025-06-06T17:52:18.065406Z",
          "iopub.status.idle": "2025-06-06T18:29:10.578226Z",
          "shell.execute_reply.started": "2025-06-06T17:52:18.065384Z",
          "shell.execute_reply": "2025-06-06T18:29:10.577398Z"
        },
        "id": "RU-L7qo7LZDn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Saving Model Statistics"
      ],
      "metadata": {
        "id": "lZWtoHZ5nV2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Collect Results**\n",
        "   - Convert `trained_models` dict → list of dicts  \n",
        "   - Each row = {\"Model\": model_name, metrics...}  \n",
        "\n",
        "2. **Create DataFrame**\n",
        "   - `results_df = pd.DataFrame([...])`  \n",
        "   - Columns: `Model`, `train_mae`, `train_rmse`, `test_mae`, `test_rmse`  \n",
        "\n",
        "3. **Sort Results**\n",
        "   - Sort by `test_mae` (ascending → best first)  \n",
        "\n",
        "4. **Display**\n",
        "   - Show top 50 models with lowest test MAE  "
      ],
      "metadata": {
        "id": "Z5UcFiadzhcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "results_df = pd.DataFrame([\n",
        "    {\"Model\": name, **metrics}\n",
        "    for name, metrics in trained_models.items()])\n",
        "\n",
        "results_df.sort_values(by = 'test_mae', ascending = True).head(50)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-06T18:29:10.579629Z",
          "iopub.execute_input": "2025-06-06T18:29:10.579884Z",
          "iopub.status.idle": "2025-06-06T18:29:10.664738Z",
          "shell.execute_reply.started": "2025-06-06T18:29:10.579854Z",
          "shell.execute_reply": "2025-06-06T18:29:10.663986Z"
        },
        "id": "FgrZgr6ELZDn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Top 50 Models"
      ],
      "metadata": {
        "id": "7lTa2Ra1nZC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Select Top 50**\n",
        "   - Sort `results_df` by `test_mae`  \n",
        "   - Keep best 50 models  \n",
        "\n",
        "2. **Create Figure**\n",
        "   - `plt.figure(figsize=(25, 8))` → wide chart for readability  \n",
        "\n",
        "3. **Plot Lines**\n",
        "   - Plot `train_mae` with markers  \n",
        "   - Plot `test_mae` with markers  \n",
        "\n",
        "4. **Customize**\n",
        "   - Rotate x-axis labels (75°) for clarity  \n",
        "   - Add labels (x, y), title, legend, and grid  \n",
        "   - `tight_layout()` → avoid overlap  \n",
        "\n",
        "5. **Show Chart**\n",
        "   - `plt.show()` → display line chart comparing Train vs Test MAE"
      ],
      "metadata": {
        "id": "uNcKIx3czj45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "top_50 = results_df.sort_values(by='test_mae', ascending=True).head(50)\n",
        "\n",
        "plt.figure(figsize=(25, 8))\n",
        "plt.plot(top_50['Model'], top_50['train_mae'], marker='o', label='Train MAE')\n",
        "\n",
        "plt.plot(top_50['Model'], top_50['test_mae'], marker='o', label='Test MAE')\n",
        "\n",
        "plt.xticks(rotation=75)\n",
        "plt.xlabel('Model Name')\n",
        "plt.ylabel('MAE')\n",
        "plt.title('Top 50 Models: Train vs Test MAE (Line Chart)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-06T18:46:18.957411Z",
          "iopub.execute_input": "2025-06-06T18:46:18.958074Z",
          "iopub.status.idle": "2025-06-06T18:46:19.504977Z",
          "shell.execute_reply.started": "2025-06-06T18:46:18.958047Z",
          "shell.execute_reply": "2025-06-06T18:46:19.504185Z"
        },
        "id": "yHf0eXA_LZDo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Relation btw. No of Input Days and Model Performance"
      ],
      "metadata": {
        "id": "LasAkREJnhWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Extract Time Windows**\n",
        "   - From each model name in `top_50`  \n",
        "   - Split string by `_` → take last part (time window)  \n",
        "\n",
        "2. **Count Frequencies**\n",
        "   - `value_counts()` → count models per time window  \n",
        "   - Sort by count (descending)  \n",
        "\n",
        "3. **Plot Bar Chart**\n",
        "   - X-axis: time windows  \n",
        "   - Y-axis: number of models in Top 50  \n",
        "\n",
        "4. **Customize**\n",
        "   - Add labels (x, y), title  \n",
        "   - Grid only on Y-axis for readability  \n",
        "   - `tight_layout()` → clean layout  \n",
        "\n",
        "5. **Show Chart**\n",
        "   - `plt.show()` → display bar chart of time-window frequencies  "
      ],
      "metadata": {
        "id": "5sKZSwwzz5X4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_50 = results_df.sort_values(by='test_mae', ascending=True).head(50)\n",
        "time_windows = pd.Series([i.split('_')[-1] for i in top_50['Model']])\n",
        "time_counts = time_windows.value_counts().sort_values(ascending=False)  # Sort by count\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(time_counts.index, time_counts.values)\n",
        "\n",
        "# Labels and aesthetics\n",
        "plt.xlabel('Time Window (Days)')\n",
        "plt.ylabel('Number of Models in Top 50')\n",
        "plt.title('Frequency of Time Windows Among Top 50 Models (Lowest Test MAE)')\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-06T18:51:59.988947Z",
          "iopub.execute_input": "2025-06-06T18:51:59.989222Z",
          "iopub.status.idle": "2025-06-06T18:52:00.160268Z",
          "shell.execute_reply.started": "2025-06-06T18:51:59.989204Z",
          "shell.execute_reply": "2025-06-06T18:52:00.159611Z"
        },
        "id": "ysw4KFEKLZDo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Which column(HIGH/LOW/CLOSE/OPEN) should be taken into considration for model building?"
      ],
      "metadata": {
        "id": "wcHGLKcZLZDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Select Top 50 Models**\n",
        "   - Sort by `test_mae` → best 50 models  \n",
        "\n",
        "2. **Extract Target Column**\n",
        "   - From model names → split by `_`  \n",
        "   - Take second last part as target column name  \n",
        "\n",
        "3. **Count Frequencies**\n",
        "   - `value_counts()` → count occurrences of each target  \n",
        "   - Sort by frequency (descending)  \n",
        "\n",
        "4. **Plot Bar Chart**\n",
        "   - X-axis: target column names  \n",
        "   - Y-axis: number of models in Top 50  \n",
        "\n",
        "5. **Customize**\n",
        "   - Add labels, title  \n",
        "   - Grid on Y-axis for readability  \n",
        "   - Use `tight_layout()` to prevent label overlap  \n",
        "\n",
        "6. **Show Chart**\n",
        "   - `plt.show()` → display bar chart of target column frequencies"
      ],
      "metadata": {
        "id": "Iei2Dk8Z0ShT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Extract target columns from top 50 models\n",
        "top_50 = results_df.sort_values(by='test_mae', ascending=True).head(50)\n",
        "target_columns = pd.Series([i.split('_')[-2] for i in top_50['Model']])\n",
        "target_counts = target_columns.value_counts().sort_values(ascending=False)  # Sort by count\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(target_counts.index, target_counts.values)\n",
        "\n",
        "# Labels and aesthetics\n",
        "plt.xlabel('Target Column')\n",
        "plt.ylabel('Number of Models in Top 50')\n",
        "plt.title('Target Column Frequency Among Top 50 Models (Lowest Test MAE)')\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-06T18:51:11.454959Z",
          "iopub.execute_input": "2025-06-06T18:51:11.455416Z",
          "iopub.status.idle": "2025-06-06T18:51:11.615491Z",
          "shell.execute_reply.started": "2025-06-06T18:51:11.455393Z",
          "shell.execute_reply": "2025-06-06T18:51:11.614795Z"
        },
        "id": "RgCP6UJYLZDp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Which model works in general better on this task?"
      ],
      "metadata": {
        "id": "LdJvhB0zn65B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Select Top 50 Models**\n",
        "   - Sort `results_df` by `test_mae`  \n",
        "   - Keep best 50 models  \n",
        "\n",
        "2. **Extract Model Types**\n",
        "   - From model names → split by `_`  \n",
        "   - Take the first part as model type (e.g., LinearRegression, LSTM)  \n",
        "\n",
        "3. **Count Frequencies**\n",
        "   - `value_counts()` → count occurrences of each model type  \n",
        "   - Sort counts in descending order  \n",
        "\n",
        "4. **Plot Bar Chart**\n",
        "   - X-axis: model types  \n",
        "   - Y-axis: number of models in Top 50  \n",
        "\n",
        "5. **Customize**\n",
        "   - Add axis labels, title  \n",
        "   - Grid only on Y-axis  \n",
        "   - `tight_layout()` for spacing  \n",
        "\n",
        "6. **Show Chart**\n",
        "   - `plt.show()` → display bar chart of model type distribution  "
      ],
      "metadata": {
        "id": "vGamWsJf0m2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_50 = results_df.sort_values(by='test_mae', ascending=True).head(50)\n",
        "model_types = pd.Series([i.split('_')[0] for i in top_50['Model']])\n",
        "model_counts = model_types.value_counts().sort_values(ascending=False)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(model_counts.index, model_counts.values)\n",
        "\n",
        "# Labels and aesthetics\n",
        "plt.xlabel('Model Type')\n",
        "plt.ylabel('Number of Models in Top 50')\n",
        "plt.title('Model Type Frequency Among Top 50 Models (Lowest Test MAE)')\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-06T18:53:48.50602Z",
          "iopub.execute_input": "2025-06-06T18:53:48.506297Z",
          "iopub.status.idle": "2025-06-06T18:53:48.681141Z",
          "shell.execute_reply.started": "2025-06-06T18:53:48.506279Z",
          "shell.execute_reply": "2025-06-06T18:53:48.680513Z"
        },
        "id": "EB8CcFGqLZDp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11. Saving Models"
      ],
      "metadata": {
        "id": "dfzrkWKYoAGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Save Results Table**\n",
        "   - `results_df.to_csv('models.csv')` → save metrics as CSV  \n",
        "\n",
        "2. **Save Trained Models**\n",
        "   - `joblib.dump(trained_models, 'trained_models.joblib')`  \n",
        "   - Stores all fitted ML + DL models + their metrics  \n",
        "\n",
        "3. **Load Models**\n",
        "   - `loaded_models = joblib.load('trained_models.joblib')`  \n",
        "   - Reload models/metrics into memory for reuse  "
      ],
      "metadata": {
        "id": "kvsy4wP00s28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "results_df.to_csv('models.csv')\n",
        "joblib.dump(trained_models, 'trained_models.joblib')\n",
        "\n",
        "loaded_models = joblib.load('trained_models.joblib')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-06T18:29:52.066922Z",
          "iopub.execute_input": "2025-06-06T18:29:52.067187Z",
          "iopub.status.idle": "2025-06-06T18:29:52.139102Z",
          "shell.execute_reply.started": "2025-06-06T18:29:52.067169Z",
          "shell.execute_reply": "2025-06-06T18:29:52.138433Z"
        },
        "id": "jaa0zh43LZDp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 12. Loading Saved Models"
      ],
      "metadata": {
        "id": "01rYsf79oE_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Access Specific Model**\n",
        "   - `loaded_models['KNN_High_90']`  \n",
        "   - Retrieves dictionary with:\n",
        "     - Trained model object  \n",
        "     - Train/Test MAE & RMSE metrics  \n",
        "\n",
        "2. **Extract Model**\n",
        "   - `model = loaded_models['KNN_High_90']['model']`  \n",
        "   - Assigns the trained KNN regressor to `model` variable  \n",
        "   - Now can be used for `.predict()` on new data  "
      ],
      "metadata": {
        "id": "e2hQXCP80y-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_models['KNN_X_High_90']\n",
        "model = loaded_models['KNN_X_High_90']['model']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-06T18:57:03.03411Z",
          "iopub.execute_input": "2025-06-06T18:57:03.034368Z",
          "iopub.status.idle": "2025-06-06T18:57:03.039273Z",
          "shell.execute_reply.started": "2025-06-06T18:57:03.03435Z",
          "shell.execute_reply": "2025-06-06T18:57:03.038559Z"
        },
        "id": "MOnBiRamLZDp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13. Model Inference"
      ],
      "metadata": {
        "id": "Fsy7XbSuoJHJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Inspect Input Sample**\n",
        "   - `print(chunked_data['X_Open_90'][5])`  \n",
        "   - Displays the 6th sample from feature set `X_Open_90`  \n",
        "\n",
        "2. **Make Prediction**\n",
        "   - `model.predict([chunked_data['X_Open_90'][5]])`  \n",
        "   - Wrap sample in a list → ensures 2D shape `(1, n_features)`  \n",
        "   - Outputs predicted value for that input using trained KNN model  "
      ],
      "metadata": {
        "id": "Ui1pQ4C104Vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunked_data['X_Open_90'][5])\n",
        "print(model.predict([chunked_data['X_Open_90'][5]]))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-06T18:57:16.974178Z",
          "iopub.execute_input": "2025-06-06T18:57:16.974433Z",
          "iopub.status.idle": "2025-06-06T18:57:16.978099Z",
          "shell.execute_reply.started": "2025-06-06T18:57:16.974415Z",
          "shell.execute_reply": "2025-06-06T18:57:16.977489Z"
        },
        "id": "y9mRYxQ0LZDp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0ebe08f"
      },
      "source": [
        "### Project Conclusion\n",
        "\n",
        "Based on the analysis of the trained models, the following conclusions can be drawn:\n",
        "\n",
        "*   **Best Performing Models:** From the analysis of the top 50 models by test MAE, it appears that **KNN, Ridge, Linear Regression, and RandomForest** models are the most frequent model types among the top performers. LightGBM also appears, but less frequently. Deep learning models (RNN, LSTM, GRU, Bidirectional LSTM) did not appear in the top 50 models in this particular experiment.\n",
        "*   **Optimal Time Windows:** The bar chart showing the frequency of time windows among the top 50 models indicates that **30, 90, and 120-day time windows** were most represented among the best-performing models. This suggests that these shorter to medium-term time horizons might be more relevant for predicting NIFTY 50 prices with the chosen models and data.\n",
        "*   **Influential Target Column:** The analysis of target column frequency among the top 50 models clearly shows that models trained on the **'High'** column significantly dominate the top performers. This suggests that predicting the 'High' price might be an easier or more predictable task using the historical price data compared to 'Open', 'Close', or 'Low'.\n",
        "\n",
        "**Further Steps:**\n",
        "\n",
        "The final assignment provides an opportunity to delve deeper into hyperparameter tuning for the most promising model and time window combinations identified in this analysis. This could potentially lead to further improvements in model performance and a more robust stock price prediction system.\n",
        "\n",
        "**[Double click to add your final thoughts and conclusions here]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0115d0ef"
      },
      "source": [
        "## 14. Final Assignment: Hyperparameter Tuning (Revised)\n",
        "\n",
        "In this final assignment, you will focus on improving the performance of the best models using a structured and simplified approach.\n",
        "\n",
        "### 1. Select Top Models\n",
        "- From the **top 50 best-performing models**, identify the **top 5 machine learning (ML) models** based on lowest test MAE.\n",
        "- Consider only these top 5 ML models for further experiments.\n",
        "\n",
        "### 2. Define Time Windows\n",
        "- Use **multiple time windows with a 5-day step size**, starting from **5 days up to 150 days**.  \n",
        "- Example time windows:  \n",
        "  `[5, 10, 15, 20, ..., 150]`\n",
        "\n",
        "### 3. Choose Promising Model–Window Combinations\n",
        "- For each of the top 5 ML models, identify the time windows that showed the best performance.\n",
        "- Select a few promising **model + time window** combinations for tuning.\n",
        "\n",
        "### 4. Hyperparameter Tuning\n",
        "- Perform hyperparameter tuning for the selected combinations.\n",
        "- Use a **small and focused set of hyperparameter values** to keep the process efficient.\n",
        "- Apply appropriate tuning techniques (e.g., grid search or manual tuning).\n",
        "\n",
        "### 5. Train Deep Learning Models\n",
        "- Train all selected **deep learning (DL) models for 50 epochs** using the chosen time windows.\n",
        "- Use the optimized hyperparameters obtained from tuning.\n",
        "\n",
        "### 6. Model Evaluation\n",
        "- Evaluate all tuned models using:\n",
        "  - **MAE (Mean Absolute Error)**\n",
        "  - **RMSE (Root Mean Squared Error)**\n",
        "- Compare the tuned models against their original (non-tuned) versions.\n",
        "\n",
        "### 7. Documentation and Conclusion\n",
        "- Summarize the following in a markdown cell:\n",
        "  - Selected models and time windows\n",
        "  - Hyperparameter tuning approach\n",
        "  - Performance comparison (before vs after tuning)\n",
        "  - Final best-performing model\n",
        "- Clearly explain **why the best tuned model performed better** than the others."
      ]
    }
  ]
}